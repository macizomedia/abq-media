# Deep Research Brief

## Context
- Source URL: 
- Source type: YouTube video
- Output language target: es

## Main Talking Points Extracted
1. Current
projections I'm just it's not that
unusual to think that a average worker
consumption model will hit 10 billion
tokens annually within the next year and
a half on average right and you may be
over a 100red billion tokens very easily
with top users.
2. And I do wonder if one
of the ways forward here is that the
workstations we're going to be using at
the enterprise will remain pretty dumb,
but we will buy that scarce cloud
capacity, which is exactly what the
hyperscalers would want because cloud
providers will offer substantial
discounts for committed user agreements.
3. You need to plan for refresh cycles that
coincide with hardware generations
because every 18 to 24 months there's
going to be a new GPU architecture that
arrives with a really significant
capability improvement you're going to
want.
4. Those that don't
are going to find themselves capacity
constrained and cost pressured and
they're going to be falling behind in
the biggest technology race in history.
5. At 10
billion tokens per worker, the same
organization is now going to consume a
100red trillion tokens a year.
6. Because supply
cannot respond to demand and demand
cannot be deferred, prices are going to
spike.
7. Microsoft, Google, Amazon,
Meta, and Oracle have collectively
committed to hundreds of billions in
Nvidia purchases over the next several
years because of the demand I've been
talking about.
8. They're going to underinvest in
flexibility and optionality and they're
going to assume supply availability that
isn't really there.

## Transcript Excerpt
We built an economy that runs on AI and
now there isn't enough compute to run
that economy. A structural crisis is
emerging in global technology
infrastructure. Over the past three
years, the world economy has reorganized
itself around AI capabilities. It's now
the biggest capex project in human
history. And those capabilities depended
entirely on inference compute. That
compute is now physically constrained
and no relief is expected before 20.
Discussion documents the nature of what
is going on. explains why it differs
from previous technology supply
crunches. And we're going to analyze the
strategic implications for enterprises
and provides some actionable guidance
for leaders who have to figure out how
to navigate the next 24 months. Just
before we get into it, I'm not going to
hide the ball. These are the top things
that are popping up for me as I dig into
this issue. Number one, demand remains
exponential and uncapped. That is the
first big driver here. Enterprise AI
consumption is growing at least at 10x
annually driven by per worker usage
increases and the proliferation of
agentic systems. There is no ceiling.
Number two, supply is physically
constrained all the way through 2028 at
least. DRAM fabrication takes 3 to four
years at semiconductor capacity is fully
allocated. High bandwidth memory is sold
out. New capacity literally cannot
arrive fast enough. Number three, all of
the hyperscalers are hoarding. Google,
Microsoft, Amazon, Meta, they've all
locked up compute allocation for years
in advance. So have open AI. So is
anthropic. They are using it to power
their own products while enterprises
compete for what remains. Number four,
pricing is going to spike. It will not
rise gradually. When demand exceeds
supply this structurally and this
severely, markets do not clear very
smoothly. Trend Force projects memory
costs alone will add 40 to 60% to
inference infrastructure in the first
half of 2026. Effective inference costs
could double or triple within 18 months.
Next, traditional planning frameworks
are broken. Capex models, depreciation
schedules, and multi-year procurement
cycles all assume predictable demand and
available supply. Neither assumption
h

## Instructions for Deep Research Agent
You are conducting deep research from this video's thesis and claims.

Deliver the output in Spanish and structure it as:

1) **Tesis central**
- Resumir el argumento principal en 3-5 líneas.

2) **Matriz de verificación de afirmaciones**
- Tabla/bullets con: afirmación, estado (confirmada/incierta/refutada), evidencia, fuente.
- Priorizar fuentes primarias y reportes institucionales.

3) **Contraargumentos y puntos ciegos**
- Qué omite el video
- Qué hipótesis alternativas existen

4) **Implicaciones estratégicas**
- Geopolítica
- Mercados
- Política pública
- Riesgo operativo

5) **Escenarios**
- 3 meses, 12 meses, 36 meses
- Señales tempranas a monitorear

6) **Guion base para podcast (español)**
- Hook de 30-45 segundos
- Desarrollo en 5 bloques
- Cierre con 3 takeaways accionables

Rules:
- Citar fuentes con enlaces.
- Separar hechos de inferencias.
- Declarar incertidumbre explícitamente.
- Evitar lenguaje hype/no verificable.

